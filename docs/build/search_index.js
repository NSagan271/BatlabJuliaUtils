var documenterSearchIndex = {"docs":
[{"location":"#BatlabJuliaUtils-Documentation","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"","category":"page"},{"location":"#Some-Julia-Notes","page":"BatlabJuliaUtils Documentation","title":"Some Julia Notes","text":"","category":"section"},{"location":"#Keyword-Arguments-(kwargs...-Notation)","page":"BatlabJuliaUtils Documentation","title":"Keyword Arguments (kwargs...  Notation)","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"If a function is as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"function helloworld(a; kwargs)","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"then you can pass in any keyword arguments you want, as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"helloworld(2; b=3, c=\"hello\");","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"The use of these keyword arguments, when present, is described in the documentation.","category":"page"},{"location":"#Plotting","page":"BatlabJuliaUtils Documentation","title":"Plotting","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"As Julia has some issues with plotting in Jupyter notebooks, it's recommended to use the Plotting Helpers listed here. If you use one of the built-in Julia plot functions, you can pass in the output of getplottingsettings as keyword arguments as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"plot(x_data, y_data; getplottingsettings(\"x label\", \"y label\", \"my title\")...);","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"Otherwise, the plot will show up as tiny unless you pass in the keyword argument html_output_format=:png, and the axis labels may be cut off unless you pass in left_margin=10Plots.mm and bottom_margin=10Plots.mm.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"Also, if some plotting function is not producing an output in a Jupyter notebook, make sure there is no semicolon at the end of the statement.","category":"page"},{"location":"#Defaults.jl","page":"BatlabJuliaUtils Documentation","title":"Defaults.jl","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"BatlabUtils/src/Defaults.jl stores default values for sampling frequencies (250 kHz for audio and 360 Hz for video), the speed of sound (344.69 m/s), default plot dimensions, and some algorithm parameters.","category":"page"},{"location":"#Plotting-Helpers","page":"BatlabJuliaUtils Documentation","title":"Plotting Helpers","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"getplottingsettings\nmyplot\nmyplot!\nplotmicdata\nplotmicdata!\nplotfftmag","category":"page"},{"location":"#BatlabJuliaUtils.getplottingsettings","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getplottingsettings","text":"getplottingsettings(xlabel::String, ylabel::String, title::String;\n    kwargs...) -> Dict{Symbol, Any}\n\nBuilds a dictionary of keyword arguments to pass into any plotting function, populated with the provided labels and titles, default font sizes and plot dimensions, and any additional keyword arguments passed into the function.\n\nInputs:\n\nxlabel: label of the x-axis.\nylabel: label of the y-axis.\ntitle: plot title.\nkwargs...: you can pass in any other keyword arguments to specify plotting   parameters or override the defaults set here.\n\nOutput:\n\nkwargs_with_defaults: dictionary of plotting keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.myplot","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.myplot","text":"myplot(args...; kwargs...)\n\nMimics Julia's plot function, except with defaults from getplottingsettings passed in. You can pass in any arguments you would to the regular plot function.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.myplot!","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.myplot!","text":"myplot!(args...; kwargs...)\n\nSame as myplot, except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmicdata","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmicdata","text":"plotmicdata(idxs::AbstractArray{Int64}, y::AbstractArray; plot_idxs=idxs,\n    kwargs...)\n\nPlot a time segment of audio data y, with milliseconds on the x-axis and voltage on the y-axis, and default plotting settings from getplottingsettings.\n\nInputs:\n\nidxs: time indices of input audio data to plot.\ny: audio data, where each column is one microphone.\nplot_idxs (default: idxs): the x-axis labels of the plot will be   audioindextoms.(plot_idxs). Use this parameter if the x-axis labels you   want don't match the value you passed in for idxs.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\nplotmicdata(y::AbstractArray; plot_idxs=1:size(y, 1), kwargs...)\n\nPlot audio data, with milliseconds on the x-axis and voltage on the y-axis, and default plotting settings from getplottingsettings. Plots the full length of y.\n\nInputs:\n\ny: audio data, where each column is one microphone.\nplot_idxs (default: 1, 2, 3,...): the x-axis labels of the plot will be   audioindextoms.(plot_idxs).\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmicdata!","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmicdata!","text":"plotmicdata!(idxs::AbstractArray{Int64}, y::AbstractArray; plot_idxs=idxs,\n    kwargs...)\n\nSame as plotmicdata(idxs, y), except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\nplotmicdata!(y::AbstractArray; plot_idxs=1:size(y, 1), kwargs...)\n\nSame as plotmicdata(y), except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotfftmag","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotfftmag","text":"plotfftmag(idxs::AbstractArray{Int64}, y::AbstractArray;\n    fft_idxs=1:length(idxs), kwargs...)\n\nPlot the Fourier transform magnitude of a time segment of real-valued time-domain audio data y.\n\nInputs:\n\nidxs: time indices of input audio data to take the Fourier transform of.\ny: time-domain audio data, where each column is one microphone.\nfft_indices (default: plot all indices): indices of the Fourier transform   to plot. Use this parameter if you only want to plot some frequencies.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\nplotfftmag(y::AbstractArray; fft_idxs=1:size(y, 1), kwargs...)\n\nPlot the Fourier transform magnitude of real-value time-domain audio data y. Takes the Fourier transform of the full length of y.\n\nInputs:\n\ny: time-domain audio data, where each column is one microphone.\nfft_indices (default: plot all indices): indices of the Fourier transform   to plot. Use this parameter if you only want to plot some frequencies.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\n","category":"function"},{"location":"#Time-Frequency-Helper-Functions","page":"BatlabJuliaUtils Documentation","title":"Time-Frequency Helper Functions","text":"","category":"section"},{"location":"#ColWiseFFTs","page":"BatlabJuliaUtils Documentation","title":"ColWiseFFTs","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"colwisefft\ncolwiseifft\nrowwisefft\nrowwiseifft","category":"page"},{"location":"#BatlabJuliaUtils.colwisefft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.colwisefft","text":"colwisefft(A::Matrix{Number}) -> Matrix{ComplexF64}\n\nApplies the Fast fourier Transform (FFT) to each column of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.colwiseifft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.colwiseifft","text":"colwiseifft(A::Matrix{Number}) -> Matrix{ComplexF64}\n\nApplies the Inverse FFT to each column of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.rowwisefft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.rowwisefft","text":"rowwisefft(A::Matrix{Number}) -> Matrix{ComplexF64}\n\nApplies the Fast fourier Transform (FFT) to each row of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.rowwiseifft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.rowwiseifft","text":"rowwiseifft(A::Matrix{Number}) -> Matrix{ComplexF64}\n\nApplies the Inverse FFT to each row of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#Convert-Data-Indices-to-Time-or-Frequency","page":"BatlabJuliaUtils Documentation","title":"Convert Data Indices to Time or Frequency","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"audioindextosec\naudioindextoms\nfftindextofrequency\ngetfftfrequencies\nvideoindextosec\nsectovideoindex\ngetvideoslicefromtimes\ngetvideodataslicefromaudioindices","category":"page"},{"location":"#BatlabJuliaUtils.audioindextosec","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.audioindextosec","text":"audioindextosec(index::Int64; fs=250 kHz) -> Float64\n\nGiven an index of the audio data, calculate the number of seconds since the beginning of the audio data.\n\nInputs:\n\nindex: index of audio data\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nSeconds since the beginning of the audio data\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.audioindextoms","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.audioindextoms","text":"audioindextoms(index::Int64; fs=250 kHz) -> Float64\n\nGiven an index of the audio data, calculate the number of milliseconds since the beginning of the audio data.\n\nInputs:\n\nindex: index of audio data\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nMilliseconds since the beginning of the audio data\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.fftindextofrequency","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.fftindextofrequency","text":"fftindextofrequency(index::Int64, N_fft::Int64; fs=250 kHz) -> Float64\n\nGiven an index of an Discrete Fourier Transform taken on a segment of audio datal determine what frequency (in Hz) it corresponds to.\n\nInputs:\n\nindex: index of the Fourier Transform.\nN_fft: length of the Fourier Transform, in samples.\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nFrequency, in Hz, of the specified Fourier Transform index\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getfftfrequencies","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getfftfrequencies","text":"getfftfrequencies(N_fft::Int64; fs=250 kHz) -> Array{Float64}\n\nReturn an array of length N_fft, where each element is the frequency, in Hz, of the corresponding index of a length-N_fft Fourier Transform of a segment of audio data.\n\nInputs:\n\nN_fft: length of the Fourier Transform, in samples.\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.videoindextosec","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.videoindextosec","text":"videoindextosec(idx_video::Int64, L_video::Int64; fs_video=360) -> Float64\n\nGiven an index of the video data, return the number of seconds since the start of the audio data.\n\nThe video and audio data are synchronized such that the end of the video data is simultaneous with the 8-second mark of the audio data.\n\nInputs:\n\nidx_video: index of the video data.\nL_video: length, in frames, of the video data.\nfs_video: sampling rate of the video data, in Hertz. Default set in    Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.sectovideoindex","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.sectovideoindex","text":"sectovideoindex(time_audio::Number, L_video::Int64; fs_video=360) -> Int64\n\nGiven a time (since the start of the audio data) in seconds, calculate the index of the closest video frame.\n\nThe video and audio data are synchronized such that the end of the video data is simultaneous with the 8-second mark of the audio data.\n\nInputs:\n\ntime_audio: time, in seconds, since the start of the audio data.\nL_video: length, in frames, of the video data.\nfs_video: sampling rate of the video data, in hertz. Default set in    Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvideoslicefromtimes","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvideoslicefromtimes","text":"getvideoslicefromtimes(location_data::Matrix{Float64}, t1::Float64,\n    t2::Float64, fs_video=360) -> UnitRange{Int64}, Matrix{Float64}\n\nReturns the video data corresponding to time interval [t1, t2] of the audio data, where t1 and t2 are in seconds.\n\nThe two datasets are synchronized as follows: the end of the video data coincides with the 8-second mark of the audio data.\n\nInputs:\n\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nt1: start time (inclusive) of interval, in seconds since the onset of the   audio data.\nt2: end time (inclusive) of interval, in seconds since the onset of the   audio data.\nfs_video (default set in Defaults.jl): sampling frequency of the centroid   data, in Hertz.\n\nOutputs:\n\nslice_idxs: indices of the audio data corresponding to the [t1, t2] slice   taken.\ncentroid_slice: centroid data in the interval [t1, t2].\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvideodataslicefromaudioindices","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvideodataslicefromaudioindices","text":"getvideodataslicefromaudioindices(location_data::Matrix{Float64},\n    t1_idx::Float64, t2_idx::Float64, fs_video=360, FS=250k) \n                                    -> UnitRange{Int64}, Matrix{Float64}\n\nSame as getvideoslicefromtimes, but takes audio data indices in lieu of times.\n\nInputs:\n\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nt1_idx: index of the audio data (inclusive) at which to start the centroid   data slice.\nt2_idx: index of the audio data (inclusive) at which to end the centroid   data slice.\nfs_video (default set in Defaults.jl): sampling frequency of the centroid   data, in Hertz.\nfs (default set in Defaults.jl): sampling frequency of the audio   data, in Hertz.\n\nOutputs: see getvideoslicefromtimes\n\n\n\n\n\n","category":"function"},{"location":"#Short-Time-Fourier-Transforms-(STFTs)-and-Spectrograms","page":"BatlabJuliaUtils Documentation","title":"Short-Time Fourier Transforms (STFTs) and Spectrograms","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"STFTwithdefaults\nplotSTFTdb\nplotSTFT\nplotSTFTtime","category":"page"},{"location":"#BatlabJuliaUtils.STFTwithdefaults","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.STFTwithdefaults","text":"STFTwithdefaults(y::AbstractArray, nfft=256,\n    noverlap=Int64(round(nfft/2)), window=hamming(nfft), zero_pad=true)\n                                                    -> Matrix{ComplexF64}\n\nWrapper around DSP.Periodograms.stft, which takes the short-time Fourier Transform (STFT) of a signal, with some reasonable default values set.\n\nInputs:\n\ny: one-dimensional signal of which to take the STFT.\nnfft (default: 256): length of each window of the STFT.\nnoverlap (default: nfft/2): overlap between adjacent STFT windows.\nwindow (default: Hamming): function multiplicatively applied to each   window to reduce spectral leakage.\nzero_pad (default: true): if set to true, zero-pad the beginning and end   of y with (nfft-1) zeros on either end.\n\nOutput:\n\nSy: STFT of y. Matrix with (nfft / 2 + 1) rows, each corresponding to a   different frequency and N columns, where N is the number of time   windows taken.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFTdb","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFTdb","text":"plotSTFTdb(Sy_db::Matrix; nfft=Int(2*floor(size(Sy_db, 1))), \n    noverlap=Int64(round(nfft/2)), crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nPlots spectrogram Sy_db, where Sy_db is in decibels (If Sy is the STFT of signal y, then Sy_db is 20 times log10 of the magnitude squared of Sy).\n\nInputs:\n\nSy_db: STFT, in decibels.\nnfft (default: 2*(height of Sy_db - 1)): length of each window of the STFT.    Used for axis labeling.\nnoverlap (default: nfft/2): overlap between adjacent STFT windows. Used for   axis labeling.\nwindow (default: Hamming): function multiplicatively applied to each   window to reduce spectral leakage.\ncrange (default: 50): the lowest value shown on the colorbar is the maximum   value of Sy_db, minus crange. All elements of Sy_db that are smaller than   this will show up in the spectrogram as this lowest value.\nfs: sampling frequency of the audio data, in Hertz. Default set in    Defaults.jl.\nplotting_kwargs: extra keyword arguments for plotting (passed into the   heatmap function).\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFT","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFT","text":"plotSTFT(Sy::Matrix{ComplexF64}; nfft=Int(2*floor(size(Sy_db, 1))), \n    noverlap=Int64(round(nfft/2)), crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nPlots the spectrogram corresponding to STFT Sy (i.e., plots a heatmap of Sy_db = 20*log10(|Sy|^2)).\n\nInputs:\n\nSy: STFT, in decibels.\nSee plotSTFTdb for the rest of the arguments.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFTtime","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFTtime","text":"plotSTFTtime(y::AbstractArray; nfft=256, noverlap=Int64(round(nfft/2)),\n    window=hamming(nfft), zero_pad=true, crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nTakes the STFT of y and then plots the spectrogram using plotSTFT.\n\nInputs:\n\ny: time-domain signal.\nnfft, noverlap, window, zero_pad: see STFTwithdefaults.\ncrange, fs, plotting_kwargs: see plotSTFTdb\n\n\n\n\n\n","category":"function"},{"location":"#Read-Audio-Data","page":"BatlabJuliaUtils Documentation","title":"Read Audio Data","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"readmicdata","category":"page"},{"location":"#BatlabJuliaUtils.readmicdata","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.readmicdata","text":"readmicdata(mat_filename::String, n_channels=4) -> Matrix{Float64}\n\nReads audio data from a MAT file into a matrix where each column represents a  different microphone.\n\nThese can be produced by running matlab_utils/tdms_to_mat.m on a TDMS file  with fields including  Voltage_0, Voltage_1, etc.\n\nInputs:\n\nmat_filename: name of a .mat file with variables Voltage_i, where   microphone index i counts up from 0, each variable is a time-series array    of voltages for the corresponding microphone, and all arrays are of the    same length.\nn_channels (default 4): number of microphones\n\nOutput:\n\ny: N x K matrix, where N is the number of samples per microphone and K    is the number of microphones. Each column corresponds to a different   microphone.\n\n\n\n\n\n","category":"function"},{"location":"#Filters","page":"BatlabJuliaUtils Documentation","title":"Filters","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"movingaveragefilter\nmaxfilter\nbandpassfilter\nbandpassfilterFFT\nbandpassfilterspecgram\ncircconv","category":"page"},{"location":"#BatlabJuliaUtils.movingaveragefilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.movingaveragefilter","text":"movingaverage(x::AbstractArray, half_len::Int64, stride=1)\n                                                    -> Matrix{Float64}\n\nApplies a symmetrical moving average filter of width 2*half_len + 1 to signal x. To make the output the same length as the input and avoid edge effects, the input is padded by duplicating the first and last elements each half_len times. The output is aligned with the input: i.e., if there is a large enough local maximum at index i of the input, there will also be a local maximum at the same index of the output.\n\nx may have multiple columns, where each column represents a different set of time-series data. In that case, the filter is applied separately to each column.\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nhalf_len: determines the length of the filter, as described above.\nstride (default: 1): if stride is not 1, then the output is downsampled   by a factor of stride.\n\nOutput:\n\ny: result of applying a moving average filter to x.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.maxfilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.maxfilter","text":"maxfilter(x::AbstractArray, half_len::Int64) -> AbstractArray{Float64}\n\nApplies a maximum filter to the input:  y[n] = maximum(x[n-half_len:n+half_len]).\n\nInput signal x may have multiple columns; each column represents a different set of time-series data.\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nhalf_len: determines the length of the filter, as described above.\n\nOutput:\n\ny: output of the filter, as described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilter","text":"bandpassfilter(x::AbstractArray, min_Hz::Number, max_Hz::Number;\n    fs=250 kHz) -> AbstractArray{Float64}\n\nApplies an ideal bandpass filter with cutoffs min_Hz and max_Hz to input signal x.\n\nInput signal x may have multiple columns; each column represents a different set of time-series data\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\ny: x, with frequencies below min_Hz or above max_Hz zeroed out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilterFFT","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilterFFT","text":"bandpassfilterFFT(x_fft::AbstractArray, min_Hz::Number, max_Hz::Number;\n    fs=250 kHz) -> AbstractArray\n\nSame as bandpassfilter, except the input and output are in the frequency domain.\n\nInputs:\n\nx_fft: input vector (or matrix) in the frequency domain.\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\ny_fft: x_fft, with frequencies below min_Hz or above max_Hz zeroed   out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilterspecgram","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilterspecgram","text":"bandpassfilterspecgram(Sx::Matrix, min_Hz::Number, max_Hz::Number;\n    nfft=2*(size(Sx, 1)-1), fs=FS) -> AbstractArray\n\nSame as bandpassfilter, except the input and output are spectrograms.\n\nInputs:\n\nSx: input spectrogram.\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nnfft (default: 2*(height of Sx-1)): size of the window used to produce   the spectrogram.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nSy: Sx, with frequencies below min_Hz or above max_Hz zeroed out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.circconv","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.circconv","text":"circconv(x::AbstractArray, h::AbstractArray; real_output=true) -> AbstractArray\n\nPerform circular convolution in the frequency domain: y = iFFT(FFT(x) * FFT(h)).\n\nInputs:\n\nx, h: two vectors of the same dimension, or matrtices where each column   is a different channel of data.\nreal_output (default: true): whether to take the real component of the   output before returning (false to leave the output a complex number).\n\nOutput:\n\ncircular convolution of x and y\n\n\n\n\n\n","category":"function"},{"location":"#Signal-to-Noise-Ratio","page":"BatlabJuliaUtils Documentation","title":"Signal-to-Noise Ratio","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"getnoisesampleidxs\nwindowedenergy\nestimatesnr","category":"page"},{"location":"#BatlabJuliaUtils.getnoisesampleidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getnoisesampleidxs","text":"getnoisesampleidxs(mic_data::AbstractArray; window_size=200)\n                                                -> UnitRange{Int64}\n\nGiven audio data, find the longest segment that is just noise.\n\nFirst, the algorithm divides the data into segments of length window_size. The amplitude of a window is defined as the maximum deviation of mic_data from its mean (over the window). The maximum noise level is set at twice the minimum amplitude of any window. The algorithm finds the indices of the longest section of mic_data where no window has an amplitude above the noise level.\n\nInputs:\n\nmic_data: matrix of audio data, where each column is a different channel.\nwindow_size: length of the windows described above.\n\nOutputs:\n\nUnitRange (i.e., the datatype of the object 1:10) of the indices of the   longest segment of the data that is only noise.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.windowedenergy","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.windowedenergy","text":"windowedenergy(x::AbstractArray, window_size::Int64; window=hamming(nfft))\n                                                        -> Matrix{Float64}\n\nFinds the energy over sliding windows of the signal x, where the windows have stride 1 (i.e., if the first window starts at index 1, the second window starts at index 2, etc.)\n\nInputs:\n\nx: vector of data, or matrix where each column is a different channel of   data.\nwindow_size (default: 64): window length, in samples.\nwindow (default: ones(window_size)): vector to multiply each window by.   The default, ones, multiplies each element by 1. To emphasize the center   of long windows, you can use windows like hamming(window_size) from the   DSP package.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatesnr","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatesnr","text":"estimatesnr(y::AbstractArray, noise_sample::AbstractArray, window_size=256,\n    window=ones(window_size)) -> Matrix{Float64}\n\nCrude estimate of the signal-to-noise ratio of the input signal y. The signal and noise levels are computed by taking the energy over sliding windows (with stride 1) of y and noise_sample, respectively. The SNR is estimated as the signal level of each window, divided by the mean noise level.\n\nInputs:\n\ny: input signal, which may be a vector, or a matrix where each column is a   different channel.\nnoise_sample: sample of noise, with the same number of channels as y.\nwindow_size (default: 64): window length, in samples.\nwindow (default: ones(window_size)): vector to multiply each window by.   The default, ones, multiplies each element by 1. To emphasize the center   of long windows, you can use windows like hamming(window_size) from the   DSP package.\n\nOutput:\n\nsnr_est: estimated SNR, in decibels (log scale, times 20) of every   timepoint in y.\n\n\n\n\n\n","category":"function"},{"location":"#Chirp-Sequences","page":"BatlabJuliaUtils Documentation","title":"Chirp Sequences","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"ChirpSequence\ngetboundsfromboxes\nfindhighsnrregions\nfindroughchirpsequenceidxs\nadjustsequenceidxs\ngetvocalizationtimems\ngroupchirpsequencesbystarttime\nplotchirpsequence","category":"page"},{"location":"#BatlabJuliaUtils.ChirpSequence","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.ChirpSequence","text":"struct ChirpSequence\n    start_idx::Int64\n    length::Int64\n    vocalization_time_ms::Float64\n    snr_data::Vector{Float64}\n    mic_data::Vector{Float64}\n    mic_num::Int64\nend\n\nDatastructure to store individual chirp sequences (for a single microphone).\n\nFields:\n\nstart_idx: start of the chirp, in numner of samples since the beginning of   the audio data.\nlength: length, in audio samples, of the chirp sequence.\nvocalization_time_ms: time (since the beginning of the audio data) that the   bat made the vocalization. Estimated using the centroid data.\nsnr_data: vector of estimated SNR values over the duration of the chirp   sequence. Produced by estimatesnr.\nmic_data: audio data for the given microphone, over the duration of the   chirp sequence.\nmic_num: which microphone (from 1 to 4) the data corresponds to.\n\n\n\n\n\n","category":"type"},{"location":"#BatlabJuliaUtils.getboundsfromboxes","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getboundsfromboxes","text":"getboundsfromboxes(boxes; filter_fn=(start_idx, stop_idx) -> true)\n    -> Matrix{Int64}\n\nGiven bitarray boxes (as a column vector), return a matrix where the first column is the start indices of the sections where boxes==1, and the second column is the end indices of those sections.\n\nOptionally, only keep boxes where filter_fn returns true.\n\nInputs:\n\nboxes: one-dimensional bitarray.\nfilter_fn (default: always return true): function that takes in the start   and end indices of a region where boxes==1 and returns false for boxes   to discard.\n\nOutput:\n\nbounds: two-column matrix, as described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.findhighsnrregions","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findhighsnrregions","text":"findhighsnrregions(snr::AbstractArray; signal_thresh::Float64,\n    peak_thresh::Float64, maxfilter_length::Int64) -> BitArray\n\nGiven the estimated SNR of the audio data (from the function estimatesnr), determine which regions are likely to contain chirp sequences, as follows:\n\nApply a maxfilter to the snr array: this helps us find contiguous  regions with high SNR.\nFind all sections where the maxfiltered SNR is above signal_thresh.\nOf those sections, keep the ones where, at some point, the SNr goes above  peak_thresh.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr, either the   full matrix or one column.\nsignal_thresh, peak_thresh: thresholds, described above.\nmaxfilter_length: half-length, in samples, of the maximum filter.\n\nOutput:\n\nhigh_snr_locations: bitarray that is 1 in regions that likely contain   chirp sequences.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.findroughchirpsequenceidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findroughchirpsequenceidxs","text":"findroughchirpsequencebounds(snr::Matrix{Float64}, mic::Int64,\n    signal_thresh::Number, peak_thresh::Number, maxfilter_length::Int64)\n                                                        -> Matrix{Int64}\n\nFor a single microphone/channel, converts the output of findhighsnrregions to a two-column matrix, where the first column is the start index of each presumed chirp sequence.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr (full    matrix).\nsignal_thresh, peak_thresh: thresholds, described in   findhighsnrregions.\nmaxfilter_length: half-length, in samples, of the maximum filter.\n\nOutput: described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.adjustsequenceidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.adjustsequenceidxs","text":"adjustsequencebounds(snr::Matrix{Float64}, mic::Int64,\n    rough_bounds::Vector{Int64}, max_end_idx::Int64; tail_snr_thresh::Real,\n    max_seq_len=MAX_SEQUENCE_LENGTH, maxfilter_seq_end=50) -> Vector{Int64}\n\nGiven rough bounds for a single chirp sequence (one row of the output of findroughchirpsequenceidxs), adjust the end index to ensure that the chirp sequence isn't cut off early.\n\nThe process is similar to findhighsnrregions, but with more lenient thresholds.\n\nApply a maxfilter to the snr array, with a filter size that is ideally  longer than the one used for findroughchirpsequenceidxs.\nFind the first index of the maxfiltered SNRs that goes below  tail_snr_thresh, a threshold lower than the one used for  findroughchirpsequenceidxs, and sets the end index of the chirp  sequence to this. If this index is beyond max_end_idx, then the end of  the chirp sequence is set to max_end_idx.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr (full    matrix).\nmic: microphone number, from 1 to 4.\nrough_bounds: row of the matrix produced by findroughchirpsequenceidxs.\nmax_end_idx: the start of the next chirp sequence, or the end of the signal       if this is the last chirp sequence for a particular microphone.\ntail_snr_thresh: described above.\nmax_seq_len maximum length of the chirp sequence. Default set in   Defaults.jl.\nmaxfilter_length (default: 50): half-length, in samples, of the maximum   filter.\n\nOutput:\n\nrefined_bounds: two-element vector, where the first element is the start   of the chirp sequence (unchanged), and the second element is the \n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvocalizationtimems","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvocalizationtimems","text":"getvocalizationtimems(chirp_start_index::Int64, mic::Int64,\n    location_data::Matrix{Float64}, mic_positions::Matrix{Float64}; \n    buffer_time_ms=100, fs_video=360,\n    interp_type=QuadraticInterpolation) -> Float64\n\nGiven the index of the audio data at which a chirp sequence starts, estimate the time that the bat made a vocalization, in milliseconds since the start of the audio data.\n\nThis is achieved by taking a slice of the centroid data of radius buffer_time_ms around the time the chirp reached the microphone, performing quadratic interpolation of the centroid data over that slice, and solving for t in\n\ndistance_from_mic(t) = speed_of_sound * (time_chirp_reached_mic - t)\n\nto get the vocalization time.\n\nThis function returns NaN (not a number) if there isn't sufficient location data to determine the vocalization time.\n\nInputs:\n\nchirp_start_index: index of the audio data that the chirp sequence started.\nmic: microphone that heard the chirp sequence.\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nbuffer_time_ms (default: 100): radius, in milliseconds, of the slice of   centroid data to examine.\nfs_video (default set in Defaults.jl): sampling rate of the centroid   data.\ninterp_type (default: QuadraticInterpolation): type of interpolation   (from the package DataInterpolations).\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.groupchirpsequencesbystarttime","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.groupchirpsequencesbystarttime","text":"groupchirpsequencesbystarttime(chirp_sequence_bounds_per_mic::Matrix{Int64},\n    snr::Matrix{Float64}, y::Matrix{Float64},\n    location_data::Matrix{Float64}, mic_locations::Matrix{Float64},\n    single_chirp_snr_thresh=100, vocalization_start_tolerance_ms=1.5) \n                -> Vector{Dict{Int64, ChirpSequence}}, Vector{Float64}\n\nGiven start and end indices of chirp sequences, for all microphones, determine which chirp sequences came from the same initial chirp. Only keep chirp sequences arising from vocalizations heard by at least two microphones.\n\nInputs:\n\nchirp_sequence_bounds_per_mic: array of [chirp sequence indices for mic 1,   ..., chirp sequence indices for mic 4].\"Chirp sequence indices for   mic i\" is a two-column matrix where the first column is the start indices   of each chirp sequence and the second column is the corresponding end   indices.\nsnr: estimated SNR of the audio data, produced by estimatesnr.\ny: matrix of audio data, where each column is a different microphone.\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nsingle_mic_snr_thresh (default: 100): if a chirp sequence only has data   from one microphone, still store the chirp sequence if it has a SNR over   this value.\nvocalization_start_tolerance_ms (default: 1.5): if the estimated   vocalization time for two chirp sequences (for different microphones) is   within vocalization_start_tolerance_ms milliseconds, then they are   considered to be from the same vocalization.\n\nOutput:\n\nchirp_sequences: example form   [{1 -> ChirpSequences(...), 2 -> ChirpSequence(...)},    {2-> ChirpSequence(...), 4 -> ChirpSequence(...), 3 -> ChirpSequence(...)},    ...   ]   Each element of the chirp_sequences vector corresponds to all chirp   sequences arising from a single vocalization. This is represented by a   dictionary mapping microphone number to ChirpSequence structure.\nvocalization_times: vector, where each element is the estimated vocalization   time for the corresponding chirp sequence.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotchirpsequence","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotchirpsequence","text":"function plotchirpsequence(chirp_seq::Dict{Int64, ChirpSequence},\n    location_data::Matrix{Float64}; plot_separate=false,\n    plot_spectrogram=false)\n\nPlots a chirp sequence on one of three formats:\n\nIf plot_separate and plot_spectrogram are both false, it plots the  data from all microphones in the same plot.\nIf plot_spectrogram is true, then it plots the spectrogram of the  chirp sequence for each microphone (in separate plots).\nOtherwise, if plot_separate is true, it plots the time-domain  waveforms for each microphone (in separate plots).\n\nInputs:\n\nchirp_seq_all_mics: dictionary mapping microphone number to a   ChirpSequence object.\nplot_separate, plot_spectrogram: descibed above.\n\n\n\n\n\n","category":"function"},{"location":"#\"Melody\"","page":"BatlabJuliaUtils Documentation","title":"\"Melody\"","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"We define the \"melody\" of the vocalization as the loudest harmonic (which likely is but may not always be the first harmonic).","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"This section contains documentation for estimating the melody, as well as some basic methods for separating chirps from echos.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"findmelody\nestimatechirpend\nplotmelody\nplotmelodydb\nestimatechirp\nplotestimatedchirps","category":"page"},{"location":"#BatlabJuliaUtils.findmelody","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findmelody","text":"findmelody(chirp_seq_single_mic::ChirpSequence, peak_snr_thresh::Real;\n    nfft=256, bandpass_filter=(20_000, 100_000), maximum_melody_slope=5)\n                                                        -> Vector{Int64}\n\nGiven a chirp sequence (for a single microphone), estimate the \"melody\" (i.e., the loudest harmonic) of the vocalization using the spectrogram.\n\nThe melody is traced as follows:\n\nFind when the SNR goes over the threshold previously set for the peak SNR of  chirp sequences, and find the melody of the chirp at that point (here, the  SNR is hopefully high enough to accurately estimate the melody).\nWork backwards until the beginning of the chirp, at each index looking for  the strongest frequency within some small range of the last frequency  found. This range is determined by the parameter maximum_melody_slope.\nRepeat, but this time work towards the end of the chirp. To avoid picking up  echos, enforce that, once the slope of the melody (with respect to time)  becomes negative, it can never become positive.\n\nThe melody is computed in terms of Fourier transform indices. To find the melody in Hertz, use the fftindextofrequency function or use findmelodyhertz instead.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\nmaximum_melody_slope: maximum amount, in Fourier transform indices, that   that the melody is allowed to change from one index to the next.\n\nOutput:\n\nmelody: described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatechirpend","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatechirpend","text":"estimatechirpend(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64},\n    peak_snr_thresh::Real; nfft=256, bandpass_filter=(20_000, 100_000),\n    melody_drop_thresh_db=20, melody_thresh_db_low=-20,moving_avg_size=10)\n                                                                -> Int64\n\nGiven a chirp sequence object (from a single mic) and the melody estimated by findmelody, estimate the end index of the chirp (i.e., separate the chirp from the echos) as follows:\n\nFind the point where the melody is the strongest.\nFind the first index, after this point, where the melody strength drops over  melody_drop_thresh_db decibels from its peak value (if this cutoff value  is below melody_thresh_db_low, we instead find where the melody strength  goes below melody_thresh_db_low).  a. If the melody strength never drops below this threshold, then just return      the last index of the chirp sequence.\nApply a moving average filter to the melody strength.\nApply the following heuristic:\nThe end of the chirp is the first local minimum of the melody strength\nafter the index from step 2, or the first time the melody strength dips  below melody_thresh_db_low, whichever comes first.\nIf neither event happens, return the last index of the chirp sequence.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\nmelody_drop_thresh_db, melody_thresh_db_low (defaults: 20, -20):   described in step 2 above.\nmoving_avg_size: radius of the moving average filter from step 4 above.\n\nOutput:\n\nchirp_end_index: estimated end index of the chirp, in indices since the   start of the chirp sequence.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmelody","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmelody","text":"plotmelody(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64},\n    chirp_end=nothing; nfft=256, bandpass_filter=(20_000, 100_000))\n\nPlots the melody estimated by findmelody, overlayed on the spectrogram of the chirp sequence. Optionally, plot a vertical line at the estimated end of the chirp sequence.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\nchirp_end (default: nothing): optionally, result of estimatechirpend.   If chirp_end is nothing, then no vertical line is plotted.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmelodydb","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmelodydb","text":"plotmelodydb(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64};\n    nfft=256, bandpass_filter=(20_000, 100_000))\n\nPlots the strength of the melody estimated by findmelody, in decibels.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatechirp","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatechirp","text":"estimatechirp(chirp_seq_single_mic::ChirpSequence, peak_snr_thresh::Real;\n    nfft=256, bandpass_filter=(20_000, 100_000), maximum_melody_slope=5, \n    melody_drop_thresh_db=20, melody_thresh_db_low=-20, moving_avg_size=10)\n                                                        -> Vector{Float64}\n\nUse estimatechirpend to separate the chirp from the echos (for a single ChirpSequence object) by returning the chirp sequence up until the estimated end index.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nnfft, bandpass_filter, maximum_melody_slope: see findmelody.\nmelody_drop_thresh_db, melody_thresh_db_low, moving_avg_size: see   estimatechirpend.\n\nOutput:\n\nchirp_est: audio data of the estimated chirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotestimatedchirps","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotestimatedchirps","text":"plotestimatedchirps(chirp_seq_all_mics::Dict{Int64, ChirpSequence},\n    peak_snr_thresh::Real; nfft=256, bandpass_filter=(20_000, 100_000),\n    maximum_melody_slope=5, melody_drop_thresh_db=20,\n    melody_thresh_db_low=-20, moving_avg_size=10)\n\nPlots the result of estimatechirp, for every microphone present in chirp_seq_all_mics, by plotting the estimated chirp on top of the chirp sequence.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\nRest of the arguments: see estimatechirp.\n\n\n\n\n\n","category":"function"},{"location":"#Misc","page":"BatlabJuliaUtils Documentation","title":"Misc","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"randint\ndistancefrommic","category":"page"},{"location":"#BatlabJuliaUtils.randint","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.randint","text":"randint(end_idx::Int64) -> Int64\n\nReturns a random integer from 1 to end_idx, inclusive.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.distancefrommic","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.distancefrommic","text":"distancefrommic(location_data::Vector{Float64},\n    mic_positions::Matrix{Float64}, mic_num::Int64) -> Float64\n\nGiven one frame of centroid data, compute the distance from mic mic_num.\n\nInputs:\n\nlocation_data: one frame of centroid data, as a vector.\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nmic_num: microphone for which to compute distances.\n\nOutput: distance from mic mic_num.\n\n\n\n\n\ndistancefrommic(location_data::Matrix{Float64},\n    mic_positions::Matrix{Float64}, mic_num::Int64) -> Vector{Float64}\n\nGiven centroid data for multiple time points, compute the distance from mic mic_num (for each time point).\n\nInputs:\n\nlocation_data: slice of centroid data, where the columns represent   coordinates (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nmic_num: microphone for which to compute distances.\n\nOutput: vector of distance from mic mic_num, for each row of location_data.\n\n\n\n\n\n","category":"function"}]
}
