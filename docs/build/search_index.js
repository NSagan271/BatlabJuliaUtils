var documenterSearchIndex = {"docs":
[{"location":"#BatlabJuliaUtils-Documentation","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"","category":"page"},{"location":"#Some-Julia-Notes","page":"BatlabJuliaUtils Documentation","title":"Some Julia Notes","text":"","category":"section"},{"location":"#Keyword-Arguments-(kwargs...-Notation)","page":"BatlabJuliaUtils Documentation","title":"Keyword Arguments (kwargs...  Notation)","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"If a function is as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"function helloworld(a; kwargs)","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"then you can pass in any keyword arguments you want, as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"helloworld(2; b=3, c=\"hello\");","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"The use of these keyword arguments, when present, is described in the documentation.","category":"page"},{"location":"#Plotting","page":"BatlabJuliaUtils Documentation","title":"Plotting","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"As Julia has some issues with plotting in Jupyter notebooks, it's recommended to use the Plotting Helpers listed here. If you use one of the built-in Julia plot functions, you can pass in the output of getplottingsettings as keyword arguments as follows:","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"plot(x_data, y_data; getplottingsettings(\"x label\", \"y label\", \"my title\")...);","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"Otherwise, the plot will show up as tiny unless you pass in the keyword argument html_output_format=:png, and the axis labels may be cut off unless you pass in left_margin=10Plots.mm and bottom_margin=10Plots.mm.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"Also, if some plotting function is not producing an output in a Jupyter notebook, make sure there is no semicolon at the end of the statement.","category":"page"},{"location":"#Defaults.jl","page":"BatlabJuliaUtils Documentation","title":"Defaults.jl","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"BatlabUtils/src/Defaults.jl stores default values for sampling frequencies (250 kHz for audio and 360 Hz for video), the speed of sound (344.69 m/s), default plot dimensions, and some algorithm parameters.","category":"page"},{"location":"#Plotting-Helpers","page":"BatlabJuliaUtils Documentation","title":"Plotting Helpers","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"getplottingsettings\nmyplot\nmyplot!\nplotmicdata\nplotmicdata!\nplotfftmag","category":"page"},{"location":"#BatlabJuliaUtils.getplottingsettings","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getplottingsettings","text":"getplottingsettings(xlabel::String, ylabel::String, title::String;\n    kwargs...) -> Dict{Symbol, Any}\n\nBuilds a dictionary of keyword arguments to pass into any plotting function, populated with the provided labels and titles, default font sizes and plot dimensions, and any additional keyword arguments passed into the function.\n\nInputs:\n\nxlabel: label of the x-axis.\nylabel: label of the y-axis.\ntitle: plot title.\nkwargs...: you can pass in any other keyword arguments to specify plotting   parameters or override the defaults set here.\n\nOutput:\n\nkwargs_with_defaults: dictionary of plotting keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.myplot","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.myplot","text":"myplot(args...; kwargs...)\n\nMimics Julia's plot function, except with defaults from getplottingsettings passed in. You can pass in any arguments you would to the regular plot function.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.myplot!","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.myplot!","text":"myplot!(args...; kwargs...)\n\nSame as myplot, except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmicdata","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmicdata","text":"plotmicdata(idxs::AbstractArray{Int64}, y::AbstractArray; plot_idxs=idxs,\n    kwargs...)\n\nPlot a time segment of audio data y, with milliseconds on the x-axis and voltage on the y-axis, and default plotting settings from getplottingsettings.\n\nInputs:\n\nidxs: time indices of input audio data to plot.\ny: audio data, where each column is one microphone.\nplot_idxs (default: idxs): the x-axis labels of the plot will be   audioindextoms.(plot_idxs). Use this parameter if the x-axis labels you   want don't match the value you passed in for idxs.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\nplotmicdata(y::AbstractArray; plot_idxs=1:size(y, 1), kwargs...)\n\nPlot audio data, with milliseconds on the x-axis and voltage on the y-axis, and default plotting settings from getplottingsettings. Plots the full length of y.\n\nInputs:\n\ny: audio data, where each column is one microphone.\nplot_idxs (default: 1, 2, 3,...): the x-axis labels of the plot will be   audioindextoms.(plot_idxs).\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmicdata!","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmicdata!","text":"plotmicdata!(idxs::AbstractArray{Int64}, y::AbstractArray; plot_idxs=idxs,\n    kwargs...)\n\nSame as plotmicdata(idxs, y), except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\nplotmicdata!(y::AbstractArray; plot_idxs=1:size(y, 1), kwargs...)\n\nSame as plotmicdata(y), except adds to the last plot produced instead of making a new plot.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotfftmag","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotfftmag","text":"plotfftmag(idxs::AbstractArray{Int64}, y::AbstractArray;\n    fft_idxs=1:length(idxs), kwargs...)\n\nPlot the Fourier transform magnitude of a time segment of real-valued time-domain audio data y.\n\nInputs:\n\nidxs: time indices of input audio data to take the Fourier transform of.\ny: time-domain audio data, where each column is one microphone.\nfft_indices (default: plot all indices): indices of the Fourier transform   to plot. Use this parameter if you only want to plot some frequencies.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\nplotfftmag(y::AbstractArray; fft_idxs=1:size(y, 1), kwargs...)\n\nPlot the Fourier transform magnitude of real-value time-domain audio data y. Takes the Fourier transform of the full length of y.\n\nInputs:\n\ny: time-domain audio data, where each column is one microphone.\nfft_indices (default: plot all indices): indices of the Fourier transform   to plot. Use this parameter if you only want to plot some frequencies.\nkwargs...: you can pass in any additional keyword arguments to set plotting   parameters.\n\n\n\n\n\n","category":"function"},{"location":"#Time-Frequency-Helper-Functions","page":"BatlabJuliaUtils Documentation","title":"Time-Frequency Helper Functions","text":"","category":"section"},{"location":"#ColWiseFFTs","page":"BatlabJuliaUtils Documentation","title":"ColWiseFFTs","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"colwisefft\ncolwiseifft\nrowwisefft\nrowwiseifft","category":"page"},{"location":"#BatlabJuliaUtils.colwisefft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.colwisefft","text":"colwisefft(A::AbstractArray) -> Matrix{ComplexF64}\n\nApplies the Fast fourier Transform (FFT) to each column of input matrix A. A can also be a vector, in which case it is first transformed into a one-col matrix.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.colwiseifft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.colwiseifft","text":"colwiseifft(A::AbstractArray) -> Matrix{ComplexF64}\n\nApplies the Inverse FFT to each column of input matrix A. A can also be a vector, in which case it is first transformed into a one-col matrix.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.rowwisefft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.rowwisefft","text":"rowwisefft(A::Matrix) -> Matrix{ComplexF64}\n\nApplies the Fast fourier Transform (FFT) to each row of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.rowwiseifft","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.rowwiseifft","text":"rowwiseifft(A::Matrix) -> Matrix{ComplexF64}\n\nApplies the Inverse FFT to each row of input matrix A.\n\n\n\n\n\n","category":"function"},{"location":"#Convert-Data-Indices-to-Time-or-Frequency","page":"BatlabJuliaUtils Documentation","title":"Convert Data Indices to Time or Frequency","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"audioindextosec\naudioindextoms\nfftindextofrequency\ngetfftfrequencies\nvideoindextosec\nsectovideoindex\ngetvideoslicefromtimes\ngetvideodataslicefromaudioindices","category":"page"},{"location":"#BatlabJuliaUtils.audioindextosec","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.audioindextosec","text":"audioindextosec(index::Int64; fs=250 kHz) -> Float64\n\nGiven an index of the audio data, calculate the number of seconds since the beginning of the audio data.\n\nInputs:\n\nindex: index of audio data\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nSeconds since the beginning of the audio data\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.audioindextoms","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.audioindextoms","text":"audioindextoms(index::Int64; fs=250 kHz) -> Float64\n\nGiven an index of the audio data, calculate the number of milliseconds since the beginning of the audio data.\n\nInputs:\n\nindex: index of audio data\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nMilliseconds since the beginning of the audio data\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.fftindextofrequency","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.fftindextofrequency","text":"fftindextofrequency(index::Int64, N_fft::Int64; fs=250 kHz) -> Float64\n\nGiven an index of an Discrete Fourier Transform taken on a segment of audio datal determine what frequency (in Hz) it corresponds to.\n\nInputs:\n\nindex: index of the Fourier Transform.\nN_fft: length of the Fourier Transform, in samples.\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nFrequency, in Hz, of the specified Fourier Transform index\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getfftfrequencies","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getfftfrequencies","text":"getfftfrequencies(N_fft::Int64; fs=250 kHz) -> Array{Float64}\n\nReturn an array of length N_fft, where each element is the frequency, in Hz, of the corresponding index of a length-N_fft Fourier Transform of a segment of audio data.\n\nInputs:\n\nN_fft: length of the Fourier Transform, in samples.\nfs: sampling frequency, in Hertz. Default set in Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.videoindextosec","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.videoindextosec","text":"videoindextosec(idx_video::Int64, L_video::Int64; fs_video=360) -> Float64\n\nGiven an index of the video data, return the number of seconds since the start of the audio data.\n\nThe video and audio data are synchronized such that the end of the video data is simultaneous with the 8-second mark of the audio data.\n\nInputs:\n\nidx_video: index of the video data.\nL_video: length, in frames, of the video data.\nfs_video: sampling rate of the video data, in Hertz. Default set in    Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.sectovideoindex","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.sectovideoindex","text":"sectovideoindex(time_audio::Number, L_video::Int64; fs_video=360) -> Int64\n\nGiven a time (since the start of the audio data) in seconds, calculate the index of the closest video frame.\n\nThe video and audio data are synchronized such that the end of the video data is simultaneous with the 8-second mark of the audio data.\n\nInputs:\n\ntime_audio: time, in seconds, since the start of the audio data.\nL_video: length, in frames, of the video data.\nfs_video: sampling rate of the video data, in hertz. Default set in    Defaults.jl.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvideoslicefromtimes","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvideoslicefromtimes","text":"getvideoslicefromtimes(location_data::Matrix{Float64}, t1::Float64,\n    t2::Float64, fs_video=360) -> UnitRange{Int64}, Matrix{Float64}\n\nReturns the video data corresponding to time interval [t1, t2] of the audio data, where t1 and t2 are in seconds.\n\nThe two datasets are synchronized as follows: the end of the video data coincides with the 8-second mark of the audio data.\n\nInputs:\n\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nt1: start time (inclusive) of interval, in seconds since the onset of the   audio data.\nt2: end time (inclusive) of interval, in seconds since the onset of the   audio data.\nfs_video (default set in Defaults.jl): sampling frequency of the centroid   data, in Hertz.\n\nOutputs:\n\nslice_idxs: indices of the audio data corresponding to the [t1, t2] slice   taken.\ncentroid_slice: centroid data in the interval [t1, t2].\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvideodataslicefromaudioindices","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvideodataslicefromaudioindices","text":"getvideodataslicefromaudioindices(location_data::Matrix{Float64},\n    t1_idx::Float64, t2_idx::Float64, fs_video=360, FS=250k) \n                                    -> UnitRange{Int64}, Matrix{Float64}\n\nSame as getvideoslicefromtimes, but takes audio data indices in lieu of times.\n\nInputs:\n\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nt1_idx: index of the audio data (inclusive) at which to start the centroid   data slice.\nt2_idx: index of the audio data (inclusive) at which to end the centroid   data slice.\nfs_video (default set in Defaults.jl): sampling frequency of the centroid   data, in Hertz.\nfs (default set in Defaults.jl): sampling frequency of the audio   data, in Hertz.\n\nOutputs: see getvideoslicefromtimes\n\n\n\n\n\n","category":"function"},{"location":"#Short-Time-Fourier-Transforms-(STFTs)-and-Spectrograms","page":"BatlabJuliaUtils Documentation","title":"Short-Time Fourier Transforms (STFTs) and Spectrograms","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"STFTwithdefaults\nplotSTFTdb\nplotSTFT\nplotSTFTtime","category":"page"},{"location":"#BatlabJuliaUtils.STFTwithdefaults","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.STFTwithdefaults","text":"STFTwithdefaults(y::AbstractArray, nfft=256,\n    noverlap=Int64(round(nfft/2)), window=hamming(nfft), zero_pad=true)\n                                                    -> Matrix{ComplexF64}\n\nWrapper around DSP.Periodograms.stft, which takes the short-time Fourier Transform (STFT) of a signal, with some reasonable default values set.\n\nInputs:\n\ny: one-dimensional signal of which to take the STFT.\nnfft (default: 256): length of each window of the STFT.\nnoverlap (default: nfft/2): overlap between adjacent STFT windows.\nwindow (default: Hamming): function multiplicatively applied to each   window to reduce spectral leakage.\nzero_pad (default: true): if set to true, zero-pad the beginning and end   of y with (nfft-1) zeros on either end.\n\nOutput:\n\nSy: STFT of y. Matrix with (nfft / 2 + 1) rows, each corresponding to a   different frequency and N columns, where N is the number of time   windows taken.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFTdb","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFTdb","text":"plotSTFTdb(Sy_db::Matrix; nfft=Int(2*floor(size(Sy_db, 1))), \n    noverlap=Int64(round(nfft/2)), crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nPlots spectrogram Sy_db, where Sy_db is in decibels (If Sy is the STFT of signal y, then Sy_db is 20 times log10 of the magnitude squared of Sy).\n\nInputs:\n\nSy_db: STFT, in decibels.\nnfft (default: 2*(height of Sy_db - 1)): length of each window of the STFT.    Used for axis labeling.\nnoverlap (default: nfft/2): overlap between adjacent STFT windows. Used for   axis labeling.\nwindow (default: Hamming): function multiplicatively applied to each   window to reduce spectral leakage.\ncrange (default: 50): the lowest value shown on the colorbar is the maximum   value of Sy_db, minus crange. All elements of Sy_db that are smaller than   this will show up in the spectrogram as this lowest value.\nfs: sampling frequency of the audio data, in Hertz. Default set in    Defaults.jl.\nplotting_kwargs: extra keyword arguments for plotting (passed into the   heatmap function).\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFT","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFT","text":"plotSTFT(Sy::Matrix{ComplexF64}; nfft=Int(2*floor(size(Sy_db, 1))), \n    noverlap=Int64(round(nfft/2)), crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nPlots the spectrogram corresponding to STFT Sy (i.e., plots a heatmap of Sy_db = 20*log10(|Sy|^2)).\n\nInputs:\n\nSy: STFT, in decibels.\nSee plotSTFTdb for the rest of the arguments.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotSTFTtime","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotSTFTtime","text":"plotSTFTtime(y::AbstractArray; nfft=256, noverlap=Int64(round(nfft/2)),\n    window=hamming(nfft), zero_pad=true, crange=50, fs=250 kHz,\n    plotting_kwargs...)\n\nTakes the STFT of y and then plots the spectrogram using plotSTFT.\n\nInputs:\n\ny: time-domain signal.\nnfft, noverlap, window, zero_pad: see STFTwithdefaults.\ncrange, fs, plotting_kwargs: see plotSTFTdb\n\n\n\n\n\n","category":"function"},{"location":"#Read-Audio-Data","page":"BatlabJuliaUtils Documentation","title":"Read Audio Data","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"readmicdata","category":"page"},{"location":"#BatlabJuliaUtils.readmicdata","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.readmicdata","text":"readmicdata(mat_filename::String, n_channels=4) -> Matrix{Float64}\n\nReads audio data from a MAT file into a matrix where each column represents a  different microphone.\n\nThese can be produced by running matlab_utils/tdms_to_mat.m on a TDMS file  with fields including  Voltage_0, Voltage_1, etc.\n\nInputs:\n\nmat_filename: name of a .mat file with variables Voltage_i, where   microphone index i counts up from 0, each variable is a time-series array    of voltages for the corresponding microphone, and all arrays are of the    same length.\nn_channels (default 4): number of microphones\n\nOutput:\n\ny: N x K matrix, where N is the number of samples per microphone and K    is the number of microphones. Each column corresponds to a different   microphone.\n\n\n\n\n\n","category":"function"},{"location":"#Filters","page":"BatlabJuliaUtils Documentation","title":"Filters","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"movingaveragefilter\nmaxfilter\nbandpassfilter\nbandpassfilterFFT\nbandpassfilterspecgram\ncircconv\ndeconvolve","category":"page"},{"location":"#BatlabJuliaUtils.movingaveragefilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.movingaveragefilter","text":"movingaverage(x::AbstractArray, half_len::Int64, stride=1)\n                                                    -> Matrix{Float64}\n\nApplies a symmetrical moving average filter of width 2*half_len + 1 to signal x. To make the output the same length as the input and avoid edge effects, the input is padded by duplicating the first and last elements each half_len times. The output is aligned with the input: i.e., if there is a large enough local maximum at index i of the input, there will also be a local maximum at the same index of the output.\n\nx may have multiple columns, where each column represents a different set of time-series data. In that case, the filter is applied separately to each column.\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nhalf_len: determines the length of the filter, as described above.\nstride (default: 1): if stride is not 1, then the output is downsampled   by a factor of stride.\n\nOutput:\n\ny: result of applying a moving average filter to x.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.maxfilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.maxfilter","text":"maxfilter(x::AbstractArray, half_len::Int64) -> AbstractArray{Float64}\n\nApplies a maximum filter to the input:  y[n] = maximum(x[n-half_len:n+half_len]).\n\nInput signal x may have multiple columns; each column represents a different set of time-series data.\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nhalf_len: determines the length of the filter, as described above.\n\nOutput:\n\ny: output of the filter, as described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilter","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilter","text":"bandpassfilter(x::AbstractArray, min_Hz::Number, max_Hz::Number;\n    fs=250 kHz) -> AbstractArray{Float64}\n\nApplies an ideal bandpass filter with cutoffs min_Hz and max_Hz to input signal x.\n\nInput signal x may have multiple columns; each column represents a different set of time-series data\n\nInputs:\n\nx: input vector, or matrix where each column is a different dataset (i.e.,   channel).\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\ny: x, with frequencies below min_Hz or above max_Hz zeroed out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilterFFT","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilterFFT","text":"bandpassfilterFFT(x_fft::AbstractArray, min_Hz::Number, max_Hz::Number;\n    fs=250 kHz) -> AbstractArray\n\nSame as bandpassfilter, except the input and output are in the frequency domain.\n\nInputs:\n\nx_fft: input vector (or matrix) in the frequency domain.\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\ny_fft: x_fft, with frequencies below min_Hz or above max_Hz zeroed   out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.bandpassfilterspecgram","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.bandpassfilterspecgram","text":"bandpassfilterspecgram(Sx::Matrix, min_Hz::Number, max_Hz::Number;\n    nfft=2*(size(Sx, 1)-1), fs=FS) -> AbstractArray\n\nSame as bandpassfilter, except the input and output are spectrograms.\n\nInputs:\n\nSx: input spectrogram.\nmin_Hz: lower cutoff of the filter.\nmax_Hz: upper cutoff of the filter.\nnfft (default: 2*(height of Sx-1)): size of the window used to produce   the spectrogram.\nfs: Sampling frequency, in Hertz. Default set in Defaults.jl.\n\nOutput:\n\nSy: Sx, with frequencies below min_Hz or above max_Hz zeroed out.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.circconv","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.circconv","text":"circconv(x::AbstractArray, h::AbstractArray; real_output=true) -> AbstractArray\n\nPerform circular convolution in the frequency domain: y = iFFT(FFT(x) * FFT(h)).\n\nInputs:\n\nx, h: two vectors of the same dimension, or matrtices where each column   is a different channel of data.\nreal_output (default: true): whether to take the real component of the   output before returning (false to leave the output a complex number).\n\nOutput:\n\ncircular convolution of x and y\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.deconvolve","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.deconvolve","text":"deconvolve(Y::AbstractArray, X::AbstractArray; fft_thresh=0.1) \n                                                -> AbstractArray\n\nPerform deconvolution: i.e., given linear time-invariant system Y and input X, such that Y is X convolved with impulse response H, find H using Fourier transforms (H = iFFT(FFT(Y) ./ FFT(X))).\n\nOptionally, zero out indices of FFT(Y) ./ FFT(X) where the magnitude of  FFT(X) is above some threshold, fft_thresh.\n\nX and Y must have the same dimensions. If they are matrices, deconvolution is applied separately to each column.\n\nInputs:\n\nY: system output; either a vector or a matrix where each column is a   different data channel.\nX: system input; same dimensions as Y.\nfft_thresh (default: 0): described above.\n\nOutputs:\n\nH: estimated impulse response; same dimensions as X and Y.\n\n\n\n\n\n","category":"function"},{"location":"#Signal-to-Noise-Ratio","page":"BatlabJuliaUtils Documentation","title":"Signal-to-Noise Ratio","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"getnoisesampleidxs\nwindowedenergy\nestimatesnr","category":"page"},{"location":"#BatlabJuliaUtils.getnoisesampleidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getnoisesampleidxs","text":"getnoisesampleidxs(mic_data::AbstractArray; window_size=200)\n                                                -> UnitRange{Int64}\n\nGiven audio data, find the longest segment that is just noise.\n\nFirst, the algorithm divides the data into segments of length window_size. The amplitude of a window is defined as the maximum deviation of mic_data from its mean (over the window). The maximum noise level is set at twice the minimum amplitude of any window. The algorithm finds the indices of the longest section of mic_data where no window has an amplitude above the noise level.\n\nInputs:\n\nmic_data: matrix of audio data, where each column is a different channel.\nwindow_size: length of the windows described above.\n\nOutputs:\n\nUnitRange (i.e., the datatype of the object 1:10) of the indices of the   longest segment of the data that is only noise.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.windowedenergy","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.windowedenergy","text":"windowedenergy(x::AbstractArray, window_size::Int64; window=hamming(nfft))\n                                                        -> Matrix{Float64}\n\nFinds the energy over sliding windows of the signal x, where the windows have stride 1 (i.e., if the first window starts at index 1, the second window starts at index 2, etc.)\n\nInputs:\n\nx: vector of data, or matrix where each column is a different channel of   data.\nwindow_size (default: 64): window length, in samples.\nwindow (default: ones(window_size)): vector to multiply each window by.   The default, ones, multiplies each element by 1. To emphasize the center   of long windows, you can use windows like hamming(window_size) from the   DSP package.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatesnr","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatesnr","text":"estimatesnr(y::AbstractArray, noise_sample::AbstractArray, window_size=256,\n    window=ones(window_size)) -> Matrix{Float64}\n\nCrude estimate of the signal-to-noise ratio of the input signal y. The signal and noise levels are computed by taking the energy over sliding windows (with stride 1) of y and noise_sample, respectively. The SNR is estimated as the signal level of each window, divided by the mean noise level.\n\nInputs:\n\ny: input signal, which may be a vector, or a matrix where each column is a   different channel.\nnoise_sample: sample of noise, with the same number of channels as y.\nwindow_size (default: 64): window length, in samples.\nwindow (default: ones(window_size)): vector to multiply each window by.   The default, ones, multiplies each element by 1. To emphasize the center   of long windows, you can use windows like hamming(window_size) from the   DSP package.\n\nOutput:\n\nsnr_est: estimated SNR, in decibels (log scale, times 20) of every   timepoint in y.\n\n\n\n\n\n","category":"function"},{"location":"#Chirp-Sequences","page":"BatlabJuliaUtils Documentation","title":"Chirp Sequences","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"ChirpSequence\ngetboundsfromboxes\nfindhighsnrregions\nfindroughchirpsequenceidxs\nadjustsequenceidxs\ngetvocalizationtimems\ngroupchirpsequencesbystarttime\nplotchirpsequence\nplotchirpsequenceboxes","category":"page"},{"location":"#BatlabJuliaUtils.ChirpSequence","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.ChirpSequence","text":"struct ChirpSequence\n    start_idx::Int64\n    length::Int64\n    vocalization_time_ms::Float64\n    snr_data::Vector{Float64}\n    mic_data::Vector{Float64}\n    mic_num::Int64\nend\n\nDatastructure to store individual chirp sequences (for a single microphone).\n\nFields:\n\nstart_idx: start of the chirp, in numner of samples since the beginning of   the audio data.\nlength: length, in audio samples, of the chirp sequence.\nvocalization_time_ms: time (since the beginning of the audio data) that the   bat made the vocalization. Estimated using the centroid data.\nsnr_data: vector of estimated SNR values over the duration of the chirp   sequence. Produced by estimatesnr.\nmic_data: audio data for the given microphone, over the duration of the   chirp sequence.\nmic_num: which microphone (from 1 to 4) the data corresponds to.\n\n\n\n\n\n","category":"type"},{"location":"#BatlabJuliaUtils.getboundsfromboxes","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getboundsfromboxes","text":"getboundsfromboxes(boxes; filter_fn=(start_idx, stop_idx) -> true)\n    -> Matrix{Int64}\n\nGiven bitarray boxes (as a column vector), return a matrix where the first column is the start indices of the sections where boxes==1, and the second column is the end indices of those sections.\n\nOptionally, only keep boxes where filter_fn returns true.\n\nInputs:\n\nboxes: one-dimensional bitarray.\nfilter_fn (default: always return true): function that takes in the start   and end indices of a region where boxes==1 and returns false for boxes   to discard.\n\nOutput:\n\nbounds: two-column matrix, as described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.findhighsnrregions","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findhighsnrregions","text":"findhighsnrregions(snr::AbstractArray; signal_thresh::Float64,\n    peak_thresh::Float64, maxfilter_length::Int64) -> BitArray\n\nGiven the estimated SNR of the audio data (from the function estimatesnr), determine which regions are likely to contain chirp sequences, as follows:\n\nApply a maxfilter to the snr array: this helps us find contiguous  regions with high SNR.\nFind all sections where the maxfiltered SNR is above signal_thresh.\nOf those sections, keep the ones where, at some point, the SNr goes above  peak_thresh.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr, either the   full matrix or one column.\nsignal_thresh, peak_thresh: thresholds, described above.\nmaxfilter_length: half-length, in samples, of the maximum filter.\n\nOutput:\n\nhigh_snr_locations: bitarray that is 1 in regions that likely contain   chirp sequences.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.findroughchirpsequenceidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findroughchirpsequenceidxs","text":"findroughchirpsequencebounds(snr::Matrix{Float64}, mic::Int64,\n    signal_thresh::Number, peak_thresh::Number, maxfilter_length::Int64)\n                                                        -> Matrix{Int64}\n\nFor a single microphone/channel, converts the output of findhighsnrregions to a two-column matrix, where the first column is the start index of each presumed chirp sequence.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr (full    matrix).\nsignal_thresh, peak_thresh: thresholds, described in   findhighsnrregions.\nmaxfilter_length: half-length, in samples, of the maximum filter.\n\nOutput: described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.adjustsequenceidxs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.adjustsequenceidxs","text":"adjustsequencebounds(snr::Matrix{Float64}, mic::Int64,\n    rough_bounds::Vector{Int64}, max_end_idx::Int64; tail_snr_thresh::Real,\n    max_seq_len=MAX_SEQUENCE_LENGTH, maxfilter_seq_end=50) -> Vector{Int64}\n\nGiven rough bounds for a single chirp sequence (one row of the output of findroughchirpsequenceidxs), adjust the end index to ensure that the chirp sequence isn't cut off early.\n\nThe process is similar to findhighsnrregions, but with more lenient thresholds.\n\nApply a maxfilter to the snr array, with a filter size that is ideally  longer than the one used for findroughchirpsequenceidxs.\nFind the first index of the maxfiltered SNRs that goes below  tail_snr_thresh, a threshold lower than the one used for  findroughchirpsequenceidxs, and sets the end index of the chirp  sequence to this. If this index is beyond max_end_idx, then the end of  the chirp sequence is set to max_end_idx.\n\nInputs:\n\nsnr: estimated SNR of the audio data, produced by estimatesnr (full    matrix).\nmic: microphone number, from 1 to 4.\nrough_bounds: row of the matrix produced by findroughchirpsequenceidxs.\nmax_end_idx: the start of the next chirp sequence, or the end of the signal       if this is the last chirp sequence for a particular microphone.\ntail_snr_thresh: described above.\nmax_seq_len maximum length of the chirp sequence. Default set in   Defaults.jl.\nmaxfilter_length (default: 50): half-length, in samples, of the maximum   filter.\n\nOutput:\n\nrefined_bounds: two-element vector, where the first element is the start   of the chirp sequence (unchanged), and the second element is the \n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getvocalizationtimems","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getvocalizationtimems","text":"getvocalizationtimems(chirp_start_index::Int64, mic::Int64,\n    location_data::Matrix{Float64}, mic_positions::Matrix{Float64}; \n    buffer_time_ms=100, fs_video=360,\n    interp_type=QuadraticInterpolation) -> Float64\n\nGiven the index of the audio data at which a chirp sequence starts, estimate the time that the bat made a vocalization, in milliseconds since the start of the audio data.\n\nThis is achieved by taking a slice of the centroid data of radius buffer_time_ms around the time the chirp reached the microphone, performing quadratic interpolation of the centroid data over that slice, and solving for t in\n\ndistance_from_mic(t) = speed_of_sound * (time_chirp_reached_mic - t)\n\nto get the vocalization time.\n\nThis function returns NaN (not a number) if there isn't sufficient location data to determine the vocalization time.\n\nInputs:\n\nchirp_start_index: index of the audio data that the chirp sequence started.\nmic: microphone that heard the chirp sequence.\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nbuffer_time_ms (default: 100): radius, in milliseconds, of the slice of   centroid data to examine.\nfs_video (default set in Defaults.jl): sampling rate of the centroid   data.\ninterp_type (default: QuadraticInterpolation): type of interpolation   (from the package DataInterpolations).\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.groupchirpsequencesbystarttime","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.groupchirpsequencesbystarttime","text":"groupchirpsequencesbystarttime(chirp_sequence_bounds_per_mic::Matrix{Int64},\n    snr::Matrix{Float64}, y::Matrix{Float64},\n    location_data::Matrix{Float64}, mic_locations::Matrix{Float64},\n    single_chirp_snr_thresh=100, vocalization_start_tolerance_ms=1.5) \n                -> Vector{Dict{Int64, ChirpSequence}}, Vector{Float64}\n\nGiven start and end indices of chirp sequences, for all microphones, determine which chirp sequences came from the same initial chirp. Only keep chirp sequences arising from vocalizations heard by at least two microphones.\n\nInputs:\n\nchirp_sequence_bounds_per_mic: array of [chirp sequence indices for mic 1,   ..., chirp sequence indices for mic 4].\"Chirp sequence indices for   mic i\" is a two-column matrix where the first column is the start indices   of each chirp sequence and the second column is the corresponding end   indices.\nsnr: estimated SNR of the audio data, produced by estimatesnr.\ny: matrix of audio data, where each column is a different microphone.\nlocation_data: full centroid data, where the columns represent coordinates   (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nsingle_mic_snr_thresh (default: 100): if a chirp sequence only has data   from one microphone, still store the chirp sequence if it has a SNR over   this value.\nvocalization_start_tolerance_ms (default: 1.5): if the estimated   vocalization time for two chirp sequences (for different microphones) is   within vocalization_start_tolerance_ms milliseconds, then they are   considered to be from the same vocalization.\n\nOutput:\n\nchirp_sequences: example form   [{1 -> ChirpSequences(...), 2 -> ChirpSequence(...)},    {2-> ChirpSequence(...), 4 -> ChirpSequence(...), 3 -> ChirpSequence(...)},    ...   ]   Each element of the chirp_sequences vector corresponds to all chirp   sequences arising from a single vocalization. This is represented by a   dictionary mapping microphone number to ChirpSequence structure.\nvocalization_times: vector, where each element is the estimated vocalization   time for the corresponding chirp sequence.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotchirpsequence","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotchirpsequence","text":"function plotchirpsequence(chirp_seq::Dict{Int64, ChirpSequence},\n    location_data::Matrix{Float64}; plot_separate=false,\n    plot_spectrogram=false)\n\nPlots a chirp sequence on one of three formats:\n\nIf plot_separate and plot_spectrogram are both false, it plots the  data from all microphones in the same plot.\nIf plot_spectrogram is true, then it plots the spectrogram of the  chirp sequence for each microphone (in separate plots).\nOtherwise, if plot_separate is true, it plots the time-domain  waveforms for each microphone (in separate plots).\n\nInputs:\n\nchirp_seq_all_mics: dictionary mapping microphone number to a   ChirpSequence object.\nplot_separate, plot_spectrogram: descibed above.\nsame_length (default: true): zero-pad shorter chirp sequences at the end   so that all chirp sequences are the same length. Only relevant for   plot_separate or plot_spectrogram.\nn_cols (default: 2): number of plots per row.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotchirpsequenceboxes","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotchirpsequenceboxes","text":"plotchirpsequenceboxes(start_ms::Real, stop_ms::Real,\n    vocalization_times::Array, chirp_sequences::Array{Dict{Int64, ChirpSequence}},\n    y::Matrix{Float64}, mics=1:size(y, 2))\n\nPlots audio data (specified by matrix y) from start_ms to stop_ms milliseconds, with boxes around all chirp sequences in that interval. Estimated vocalization times are written above all boxes.\n\nInputs:\n\nstart_ms: start time of the plot, in milliseconds.\nstop_ms: stop time of the plot, in milliseconds.\nvocalization_times: list of vocalization times output by   groupchirpsequencesbystarttime.\nchirp_sequences: list of mappings from microphone to ChirpSequence object   produced by groupchirpsequencesbystarttime.\ny: matrix of microphone data, where each column is a different microphone.\nmics (default: all): microphones for which to plot chirp sequences.\n\n\n\n\n\n","category":"function"},{"location":"#\"Melody\"","page":"BatlabJuliaUtils Documentation","title":"\"Melody\"","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"We define the \"melody\" of the vocalization as the fundamental harmonic of the chirp.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"This section contains documentation for estimating the melody, as well as some basic methods for separating chirps from echos.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"findmelody\nfindmelodyhertz\ngetharmonic\nestimatechirpbounds\ngetchirpstartandendindices\nplotmelody\nplotmelodydb\nestimatechirp\nplotestimatedchirps\ncomputemelodyoffsets\nplotoffsetchirps\nseparatechirpkwargs","category":"page"},{"location":"#BatlabJuliaUtils.findmelody","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findmelody","text":"findmelody(chirp_seq_single_mic::ChirpSequence, peak_snr_thresh::Real;\n    nfft=256, bandpass_filter=(20_000, 100_000), maximum_melody_slope=5)\n                                                        -> Vector{Int64}\n\nGiven a chirp sequence (for a single microphone), estimate the \"melody\" (i.e., the fundamental harmonic) of the vocalization using the spectrogram.\n\nThe melody is traced as follows:\n\nFind when the SNR goes over the threshold previously set for the peak SNR of  chirp sequences, and find the melody of the chirp at that point (here, the  SNR is hopefully high enough to accurately estimate the melody).\nWork backwards until the beginning of the chirp, at each index looking for  the strongest frequency within some small range of the last frequency  found. This range is determined by the parameter maximum_melody_slope.\nRepeat, but this time work towards the end of the chirp. To avoid picking up  echos, enforce that, once the slope of the melody (with respect to time)  becomes negative, it can never become positive.\n\nAfter tracing the melody, we need to see if we found the fundamental harmonic or some higher harmonic. This is done by taking the loudest part of the melody and dividing the frequency by 2, 3, etc. until we go below 20 kHz. The fundamental harmonic is the lowest such frequency with power at most melody_drop_thresh_db below the loudest harmonic.\n\nThe melody is computed in terms of Fourier transform indices. To find the  melody in Hertz, use the fftindextofrequency function or use  findmelodyhertz instead.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\nmaximum_melody_slope (default: 5): maximum amount, in Fourier transform    indices, that that the melody is allowed to change from one index to the    next.\nmelody_drop_thresh_db (default: 20): used to find the fundamental harmonic; described above.\n\nOutput:\n\nmelody: described above.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.findmelodyhertz","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.findmelodyhertz","text":"findmelodyhertz(chirp_seq_single_mic::ChirpSequence, peak_snr_thresh::Real;\n    nfft=256, bandpass_filter=(20_000, 100_000), maximum_melody_slope=5,\n    fs=250_000) -> Vector{Float64}\n\nSame as findmelody, but converts the result to Hertz.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getharmonic","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getharmonic","text":"getharmonic(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64},\n    harmonic_num::Int64; nfft=256, band_size=2) -> Vector{Int64}\n\nGiven the output of findmelody for chirp_seq_single_mic, find the harmonic given by harmonic_num. This is done by searching for the strongest frequencies in a region of radius band_size around harmonic_num times the melody.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: output of findmelody.\nharmonic_num: which harmonic to find (e.g., 2, 3, etc.)\nnfft (default: 256): window size for computing the spectrogram.\nband_size (default: 2): described above.\n\nOutputs:\n\nharmonic: array that contains the estimated harmonic, in Fourier transform   indices.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatechirpbounds","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatechirpbounds","text":"    estimatechirpbounds(chirp_seq_single_mic::ChirpSequence,\n    melody::Vector{Int64}, peak_snr_thresh::Real; nfft=256,\n    bandpass_filter=(20_000, 100_000),melody_drop_thresh_db=20, melody_thresh_db_low=-20,moving_avg_size=10) -> Int64\n\nGiven a chirp sequence object (from a single mic) and the melody estimated by findmelody, estimate the end index of the chirp (i.e., separate the chirp from the echos) as follows:\n\nFind the point where the melody is the strongest.\nFind the first index, after this point, where the melody strength drops over  melody_drop_thresh_db decibels from its peak value (if this cutoff value  is below melody_thresh_db_low, we instead find where the melody strength  goes below melody_thresh_db_low).  a. If the melody strength never drops below this threshold, then just return      the last index of the chirp sequence.\nApply a moving average filter to the melody strength.\nApply the following heuristic:\nThe end of the chirp is the first local minimum of the melody strength\nafter the index from step 2, or the first time the melody strength dips  below melody_thresh_db_low, whichever comes first.\nIf neither event happens, return the last index of the chirp sequence.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\nmelody_drop_thresh_db, melody_thresh_db_low (defaults: 20, -20):   described in step 2 above.\nmelody_thresh_db_start: the start index of the chirp is computed as the   first index where the melody passes this threshold. It usually works best   when this is a bit above the melody_thresh_db_low.\nmoving_avg_size: radius of the moving average filter from step 4 above.\n\nOutput:\n\nchirp_start_index: estimated start index of the chirp, in indices since the   start of the chirp sequence.\nchirp_end_index: estimated end index of the chirp, in indices since the   start of the chirp sequence.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getchirpstartandendindices","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getchirpstartandendindices","text":"getchirpstartandendindices(\n    chirp_sequence_all_mics::Dict{Int64, ChirpSequence}, peak_snr_thresh::Real;\n    chirp_kwargs...) -> Dict{Int64, Int64}, Dict{Int64, Int64}\n\nGiven a dictionary mapping microphones to ChirpSequence objects, run findmelody and estimatechirpbounds for each ChirpSequence and return two dictionaries mapping microphones to chirp start indices and chirp end indices, respectively. Indices are calculated in samples since the start of the chirp sequence (i.e., since the beginning of the mic_data array of the ChirpSequence object).\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nchirp_kwargs: you can additionally pass in any keyword arguments for\n\nfindmelody and/or estimate_chirp_bounds.\n\nOutputs:\n\nchirp_starts: dictionary mapping microphone indices to their respective   chirp start indices (in samples since the start of the chirp sequence).\nchirp_ends: dictionary mapping microphone indices to their respective   chirp end indices (in samples since the start of the chirp sequence).\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmelody","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmelody","text":"plotmelody(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64},\n    chirp_end=nothing; nfft=256, bandpass_filter=(20_000, 100_000),\n    melody_color=\"blue\", end_color=\"cyan\")\n\nPlots the melody estimated by findmelody, overlayed on the spectrogram of the chirp sequence. Optionally, plot a vertical line at the estimated end of the chirp sequence.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\nchirp_end (default: nothing): optionally, result of estimatechirpend.   If chirp_end is nothing, then no vertical line is plotted.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\nmelody_color (default: \"blue\"): color used to plot the melody.\nend_color (default: \"cyan\"): color used to plot the vertical line at the end   of the chirp sequence.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotmelodydb","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotmelodydb","text":"plotmelodydb(chirp_seq_single_mic::ChirpSequence, melody::Vector{Int64};\n    nfft=256, bandpass_filter=(20_000, 100_000))\n\nPlots the strength of the melody estimated by findmelody, in decibels.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\nmelody: result of findmelody.\nnfft (default: 256): window size for computing the spectrogram.\nbandpass_filter (default: (20_000, 100_000)): before computing the melody,   a band-pass filter is applied to the spectrogram. bandpass_filter is a   tuple of the (lower cutoff, upper cutoff), in Hertz.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.estimatechirp","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.estimatechirp","text":"estimatechirp(chirp_seq_single_mic::ChirpSequence, peak_snr_thresh::Real;\nchirp_kwargs...) -> Int64, Vector{Float64}\n\nUse estimatechirpend to separate the chirp from the echos (for a single ChirpSequence object) by returning the chirp sequence up until the estimated end index.\n\nInputs:\n\nchirp_seq_single_mic: input chirp sequence object (for a single microphone).\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nchirp_kwargs: you can additionally pass in any keyword arguments for   findmelody and/or estimate_chirp_bounds.\n\nOutput:\n\nchirp_start: index of the chirp start, in samples since the beginning of   the chirp sequence.\nchirp_est: audio data of the estimated chirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotestimatedchirps","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotestimatedchirps","text":"plotestimatedchirps(chirp_seq_all_mics::Dict{Int64, ChirpSequence},\n    peak_snr_thresh::Real; nfft=256, bandpass_filter=(20_000, 100_000),\n    maximum_melody_slope=5, melody_drop_thresh_db=20,\n    melody_thresh_db_low=-20, moving_avg_size=10)\n\nPlots the result of estimatechirp, for every microphone present in chirp_seq_all_mics, by plotting the estimated chirp on top of the chirp sequence.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\nsame_length (default: true): whether to zero-pad the ends of chirp   sequences so that all of them are the same length.\nRest of the arguments: see estimatechirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.computemelodyoffsets","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.computemelodyoffsets","text":"computemelodyoffsets(chirp_sequence_all_mics::Dict{Int64, ChirpSequence},\n    peak_snr_thresh::Real; max_offset=500, max_negative_offset=100,\n    tolerance=1, chirp_kwargs...)\n\nSometimes, especially for noisy data, the beginnings of the chirps get cut off. This function takes in data from all (high-snr) microphones for a chirp sequence and estimates how many samples were cut off from the beginning of each chirp.\n\nIt does this by:\n\nFinding the mic with the highest SNR. This mic will be used as reference.\nFinding the melody and chirp lengths for each microphone.\nShifting the chirps for the non-reference microphones forward and backward  in time until we find the shift that minimizes the distance between that  chirp's melody and the reference microphone's melody.\n\nThis ensures that we can \"align\" all of the chirps.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nmax_offset (default: 500): maximum shift forward to try, in audio samples   (i.e., if the beginning of the chirp was cut off).\nmax_negative_offset (default: 100): maximum shift backward to try, in audio   samples (i.e., if there is some noise picked up before the beginning of the   actual chirp). This should be relatively small to avoid erroneously cutting   off the beginnings of chirps.\ntolerance (default: 1): if the offset found in step 3 does not decrease the   mean absolute error of the difference between the reference melody and the   given microphone's melody by at least tolerance, then just set the offset   to zero.\nchirp_kwargs: you can additionally pass in any keyword arguments for   findmelody and/or estimate_chirp_bounds.\n\nOutput:\n\noffsets: dictionary mapping microphone number to the best shift, in samples   of audio data, found in part 3.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.plotoffsetchirps","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.plotoffsetchirps","text":"function plotoffsetchirps(chirpseqall_mics::Dict{Int64, ChirpSequence},      offsets::Dict{Int64, Int64})\n\nPlot a chirp sequence, where the data from each microphone is shifted by the value found in computemelodyoffsets. Plots spectrograms in a vertical layout so that you can visially see if the chirps are aligned with each other.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\noffsets: output of computemelodyoffsets.\nstart_idxs: dictionary mapping microphone indices to their respective   chirp start indices (in samples since the start of the chirp sequence).   You can get this using getchirpstartandendindices.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.separatechirpkwargs","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.separatechirpkwargs","text":"separatechirpkwargs(;chirp_kwargs...) -> Dict{Symbol, Any},  \n                                         Dict{Symbol, Any},\n                                         Dict{Symbol, Any}\n\nGiven keyword arguments from a combination of findmelody, estimatechirpbounds, and computemelodyoffsets, separate them into  three dictionaries: one for each of those functions.\n\n\n\n\n\n","category":"function"},{"location":"#Optimization","page":"BatlabJuliaUtils Documentation","title":"Optimization","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"This section contains helper methods for performing blind deconvolution on a chirp sequence to estimate the initial bat vocalization.","category":"page"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"colwisenormalize\ngetchirpsequenceY\ngetinitialconditionsnr\ngetinitialconditionsparsity\ngetmelodyregularization\noptimizePALM","category":"page"},{"location":"#BatlabJuliaUtils.colwisenormalize","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.colwisenormalize","text":"colwisenormalize(Y::Matrix) -> Matrix\n\nNormalizes each column of matrix Y such that each column has an amplitude (i.e., maximum absolute value) of 1.\n\nInputs:\n\nY: matrix, where each column is a different channel of data.\n\nOutputs:\n\nY, with each column divided by its amplitude.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getchirpsequenceY","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getchirpsequenceY","text":"getchirpsequenceY(chirp_seq_all_mics::Dict{Int64, ChirpSequence},\n    offsets::Dict{Int64, Int64}, pad_len::Int64; normalize=true)\n                                    -> Matrix{Float64}, Vector{Int64}\n\nGiven chirp sequence objects (for all microphones) corresponding to the same initial vocalization, produce a matrix of microphone data, where each column is a different microphone. The microphone data is zero-padded at the beginning and the end by pad_len zeros. In addition, if the beginning of any chirp was cut off (as determined by offsets, which is the output of computemelodyoffsets), the beginning is zero-padded by the number of samples that were cut off. By default, each column of the output is normalized to have amplitude 1.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\noffsets: output of computemelodyoffsets; mapping of microphone index to   how many samples were cut off (if any) at the beginning of the chirp.\npad_len: how many zeros to add to the beginning and end of the mic data.   This is used to mitigate edge effects from circular convolution.\nnormalize (default: true): whether to ensure each column of the output   has amplitude 1.\n\nOutputs:\n\nY: L x K matrix, where L is the length of the longest chirp sequene in   chirp_seq_all_mics, plus 2*pad_len and K is the number of   microphones used.\nmics: list of microphone number, where the microphone number at each index   is the microphone used for the corresponding column of Y.\n\n\n\n\n\ngetchirpsequenceY(chirp_seq_all_mics::Dict{Int64, ChirpSequence},\n    peak_snr_thresh::Real, pad_len::Int64; normalize=true,\n    offset_kwargs...) -> Matrix{Float64}, Vector{Int64}\n\nLike the above function (getchirpsequenceY(chirp_seq_all_mics, offsets, pad_len, normalize)), except the offsets are automatically computed using computemelodyoffsets.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\npad_len: how many zeros to add to the beginning and end of the mic data.   This is used to mitigate edge effects from circular convolution.\nnormalize (default: true): whether to ensure each column of the output   has amplitude 1.\noffset_kwargs: optionally, you can pass in any keyword arguments for   computemelodyoffsets.\n\nOutputs:\n\nY: L x K matrix, where L is the length of the longest chirp sequene in   chirp_seq_all_mics, plus 2*pad_len and K is the number of   microphones used.\nmics: list of microphone number, where the microphone number at each index   is the microphone used for the corresponding column of Y.\n\n\n\n\n\ngetchirpsequenceY(chirp_seq_all_mics::Dict{Int64, ChirpSequence},\n    pad_len::Int64; normalize=true) -> Matrix{Float64}, Vector{Int64}\n\nLike the above function (getchirpsequenceY(chirp_seq_all_mics, offsets, pad_len, normalize)), except the offsets are all set to zero.\n\nInputs\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\npad_len: how many zeros to add to the beginning and end of the mic data.   This is used to mitigate edge effects from circular convolution.\nnormalize (default: true): whether to ensure each column of the output   has amplitude 1.\n\nOutputs:\n\nY: L x K matrix, where L is the length of the longest chirp sequene in   chirp_seq_all_mics, plus 2*pad_len and K is the number of   microphones used.\nmics: list of microphone number, where the microphone number at each index   is the microphone used for the corresponding column of Y.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getinitialconditionsnr","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getinitialconditionsnr","text":"getinitialconditionsparsity(Y::Matrix{Float64},\n    chirp_seq_all_mics::Dict{Int64, ChirpSequence}, mics::Vector{Int64},\n    peak_snr_thresh::Real; chirp_kwargs...) \n                                -> Vector{Float64}, Matrix{Float64}, Int64\n\nProduces an initial condition for the blind deconvolution algorithm (i.e.: an estimate of the bat chirp and the impulse responses mapping the bat chirp to the audio output of each microphone). It uses the chirp estimate (from  estimatechirp) for the highest-SNR microphone as the estimate of the bat chirp, and performs Fourier deconvolution (see the deconvolve function) to get the impulse responses.\n\nThis is the preferred method of obtaining the initial condition for noisy data.\n\nInputs:\n\nY: matrix of audio data, produced by getchirpsequenceY.\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\nmics: list of microphones used, produced by getchirpsequenceY.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nchirp_kwargs: you can pass in any keywords for estimatechirp.\n\nOutputs: \n\nX_init: estimated bat vocalization.\nH_init: matrix of estimated impulse responses, the k-th column of H_init,   convolved with X_init, produces the k-th column of Y.\nlongest_chirp: length of the longest estimated chirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getinitialconditionsparsity","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getinitialconditionsparsity","text":"getinitialconditionsparsity(Y::Matrix{Float64},\n    chirp_seq_all_mics::Dict{Int64, ChirpSequence}, mics::Vector{Int64},\n    peak_snr_thresh::Real; chirp_kwargs...) \n                                -> Vector{Float64}, Matrix{Float64}, Int64\n\nProduces an initial condition for the blind deconvolution algorithm (i.e.: an estimate of the bat chirp and the impulse responses mapping the bat chirp to the audio output of each microphone). It uses the chirp estimate (from  estimatechirp) for one of the microphones as the estimate of the bat chirp, and performs Fourier deconvolution (see the deconvolve function) to get the impulse responses. The chirp is estimated using whichever microphone produces the sparserst impulse response.\n\nThis is not recommended for noisy data; getinitialconditionsnr is better for that case.\n\nInputs:\n\nY: matrix of audio data, produced by getchirpsequenceY.\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\nmics: list of microphones used, produced by getchirpsequenceY.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nchirp_kwargs: you can pass in any keywords for estimatechirp.\n\nOutputs: \n\nX_init: estimated bat vocalization.\nH_init: matrix of estimated impulse responses, the k-th column of H_init,   convolved with X_init, produces the k-th column of Y.\nlongest_chirp: length of the longest estimated chirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.getmelodyregularization","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.getmelodyregularization","text":"function getmelodyregularization(chirpseqallmics::Dict{Int64, ChirpSequence},     N::Int64, peaksnrthresh::Real; melodyradius = 2, nfft=256,     stftstride=Int64(floor(nfft/4)), maxfreqhz=100000, chirp_kwargs...)                                                                     -> Matrix\n\nProduces a weight matrix (of the same dimensions of the STFT of a bat vocalization, where the length of the vocalization is length of the longest estimated chirp for chirp_seq_all_mics) that quantifies how far any part of the spectrogram is from the melody or one of its harmonics.\n\nDetails of the algorithm are as follows:\n\nInitialize Mx2, the element-wise square of the weight matrix, to be all  infinity.\nFor each microphone in chirp_seq_all_mics:  a. Find the melody, chirp start/end indices, and whether the beginning of      the chirp was cut off.  b. Loop through all harmonics under max_freq_hz:      i. Find the distance of each point on the spectrogram to some range          around the melody. The radius of this range is either err_radius          or the slope of the melody at the given point, whichever is larger.\n     This provides some leeway in where the actual melody falls, where the leeway is determined by how fast the melody is changing.\n ii. Set `Mx2` to the element-wise minimum of its current value and the\n     squared distance from step i.\nTruncate Mx2 to the maximum estimated chirp length.\nDownsample Mx2 by a factor of stft_stride, setting each index of the  downsampled version to the minimum value in a time radius of nfft/2.\n\nInputs:\n\nchirp_seq_all_mics: mapping of microphone index to ChirpSequence object.\nN: upper bound on the length of the bat vocalization.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\nmelody_radius (default: 2): described in step 2.b.i above.\nnfft (default: 256): window length to use for the STFT.\nstft_stride (default: nfft/4): amount to downsample in step 4 above.\nmax_freq_hz (default: 100k): used to find the highest possible harmonic.\nchirp_kwargs: optionally, you can pass in any keyward arguments for   findmelody, estimatechirpbounds, or computemelodyoffsets.\n\nOutputs:\n\nMx2: weight matrix, described above.\nmax_chirp_len: maximum chirp length from estimatechirp.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.optimizePALM","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.optimizePALM","text":"function optimizePALM(chirpseq::Dict{Int64, ChirpSequence}, Y::Matrix{Float64},      Hinit::Matrix{Float64}, Xinit::Array{Float64}, peaksnrthresh::Real,     datafittingweight::Real, sparsityweight::Real, melodyweight::Real;     maxiter=1000, alpha=1e-3, gammaH=1, gammaX=1, numdebug=10, nfft=256,     stftstride=Int64(floor(nfft/4)), chirp_kwargs...) -> Matrix, Matrix, Int64\n\nPerforms blind deconvolution, formulated as an optimization problem with a combination of the following objectives:\n\nData-fitting: making sure X, convolved with any column of H, the matrix  of impulse responses, is close to the corresponding column of Y, the  microphone data marix produced by getchirpsequenceY.\nImpulse response sparsity: encouraging sparsity of H, measured by the  absolute sum (L1 norm) of the elements of H.\nMelody following: making sure the energy of the spectrogram  of X is close  to the melody or one of its harmonics. See getmelodyregularization for  more details.\n\nThis optimization problem is solved using PALM (proximal alternating linearized optimization: https://arxiv.org/abs/1604.00526), following the general process outlined in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7730569/.\n\nInputs:\n\nchirp_seq: mapping of microphone index to ChirpSequence object.\nY: matrix of microphone data; output of getchirpsequenceY.\nH_init: initial condition for the impulse responses; output of   getinitialconditionsnr or getinitialconditionsparsity.\nX_init: initial condition for the bat vocalization. Produced by the same   function as H_init.\npeak_snr_thresh: threshold set for the peak SNR of a chirp sequence.\ndata_fitting_weight: weight of the data-fitting term in the optimization   objective. Can be thought of as a percentage of how much that term   matters (60 is a generally good value).\nsparsity_weight: weight of the sparsity term in the objective. 10 is a   generally good value.\nmelody_weight: weight of the melody-following term in the objective. 50 is   a generally good value.\nmax_iter (default: 1000): number of iterations to run the algorithm for.\nalpha (default: 0.001): the absolute sum of the elements of H is   approximated using the smooth function |x| ≈ sqrt(x^2 + alpha^2) - alpha,   where alpha is some small number\ngamma_H (default: 1): factor to slow down updates of H (must be at least   1, or the algorithm might not converge).\ngamma_X (default: 1): factor to slow down updates of X (must be at least   1, or the algorithm might not converge).\nnum_debug (default: 10): number of times to print debug statements over the   course of the optimization algorithm.\nnfft (default: 256): window length to use for the spectrogram of X.\nstft_stride (default: nfft/4): spacing between adjacent spectrogram   windows.\nchirp_kwargs: optionally, you can pass in any keyward arguments for   findmelody, estimatechirpbounds, or computemelodyoffsets.\n\nOutputs:\n\nX: bat vocalization, as estimated by the optimization algorithm,\nH: matrix of impulse responses, as estimated by the optimization algorithm.\nmax_chirp_len: maximum chirp length from estimatechirp.\n\n\n\n\n\n","category":"function"},{"location":"#Miscellaneous","page":"BatlabJuliaUtils Documentation","title":"Miscellaneous","text":"","category":"section"},{"location":"","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils Documentation","text":"randint\ndistancefrommic","category":"page"},{"location":"#BatlabJuliaUtils.randint","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.randint","text":"randint(end_idx::Int64) -> Int64\n\nReturns a random integer from 1 to end_idx, inclusive.\n\n\n\n\n\n","category":"function"},{"location":"#BatlabJuliaUtils.distancefrommic","page":"BatlabJuliaUtils Documentation","title":"BatlabJuliaUtils.distancefrommic","text":"distancefrommic(location_data::Vector{Float64},\n    mic_positions::Matrix{Float64}, mic_num::Int64) -> Float64\n\nGiven one frame of centroid data, compute the distance from mic mic_num.\n\nInputs:\n\nlocation_data: one frame of centroid data, as a vector.\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nmic_num: microphone for which to compute distances.\n\nOutput: distance from mic mic_num.\n\n\n\n\n\ndistancefrommic(location_data::Matrix{Float64},\n    mic_positions::Matrix{Float64}, mic_num::Int64) -> Vector{Float64}\n\nGiven centroid data for multiple time points, compute the distance from mic mic_num (for each time point).\n\nInputs:\n\nlocation_data: slice of centroid data, where the columns represent   coordinates (x, y, z).\nmic_positions: matrix of microphone positions, where each row is a   different microphone and the columns represent coordinates (x, y, z).\nmic_num: microphone for which to compute distances.\n\nOutput: vector of distance from mic mic_num, for each row of location_data.\n\n\n\n\n\n","category":"function"}]
}
